{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7819d91c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 29\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Step 1: Data Exploration\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# a) Load the dataset and examine its structure.\u001b[39;00m\n\u001b[0;32m     12\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStudy Hours\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3.7\u001b[39m, \u001b[38;5;241m9.5\u001b[39m, \u001b[38;5;241m7.3\u001b[39m, \u001b[38;5;241m6.0\u001b[39m, \u001b[38;5;241m1.6\u001b[39m, \u001b[38;5;241m1.6\u001b[39m, \u001b[38;5;241m0.6\u001b[39m, \u001b[38;5;241m8.7\u001b[39m, \u001b[38;5;241m6.0\u001b[39m, \u001b[38;5;241m7.1\u001b[39m,\n\u001b[0;32m     13\u001b[0m                         \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m9.7\u001b[39m, \u001b[38;5;241m8.3\u001b[39m, \u001b[38;5;241m2.1\u001b[39m, \u001b[38;5;241m1.8\u001b[39m, \u001b[38;5;241m1.8\u001b[39m, \u001b[38;5;241m3.0\u001b[39m, \u001b[38;5;241m5.2\u001b[39m, \u001b[38;5;241m4.3\u001b[39m, \u001b[38;5;241m2.9\u001b[39m,\n\u001b[0;32m     14\u001b[0m                         \u001b[38;5;241m6.1\u001b[39m, \u001b[38;5;241m1.4\u001b[39m, \u001b[38;5;241m2.9\u001b[39m, \u001b[38;5;241m3.7\u001b[39m, \u001b[38;5;241m4.6\u001b[39m, \u001b[38;5;241m7.9\u001b[39m, \u001b[38;5;241m2.0\u001b[39m, \u001b[38;5;241m5.1\u001b[39m, \u001b[38;5;241m5.9\u001b[39m, \u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m                         \u001b[38;5;241m77.1\u001b[39m, \u001b[38;5;241m59.6\u001b[39m, \u001b[38;5;241m76.2\u001b[39m, \u001b[38;5;241m86.5\u001b[39m, \u001b[38;5;241m128.8\u001b[39m, \u001b[38;5;241m109.7\u001b[39m, \u001b[38;5;241m143.5\u001b[39m, \u001b[38;5;241m99.3\u001b[39m, \u001b[38;5;241m66.1\u001b[39m,\n\u001b[0;32m     27\u001b[0m                         \u001b[38;5;241m130.8\u001b[39m, \u001b[38;5;241m124.9\u001b[39m, \u001b[38;5;241m102.4\u001b[39m, \u001b[38;5;241m122.6\u001b[39m, \u001b[38;5;241m95.3\u001b[39m, \u001b[38;5;241m101.9\u001b[39m, \u001b[38;5;241m94.5\u001b[39m, \u001b[38;5;241m53.9\u001b[39m, \u001b[38;5;241m64.9\u001b[39m]}\n\u001b[1;32m---> 29\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Display the structure of the dataset\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    703\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    704\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    705\u001b[0m     )\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 709\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    479\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:115\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:655\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    653\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    659\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    660\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Step 1: Data Exploration\n",
    "\n",
    "# a) Load the dataset and examine its structure.\n",
    "data = {'Study Hours': [3.7, 9.5, 7.3, 6.0, 1.6, 1.6, 0.6, 8.7, 6.0, 7.1,\n",
    "                        0.2, 9.7, 8.3, 2.1, 1.8, 1.8, 3.0, 5.2, 4.3, 2.9,\n",
    "                        6.1, 1.4, 2.9, 3.7, 4.6, 7.9, 2.0, 5.1, 5.9, 0.5,\n",
    "                        6.1, 1.7, 0.7, 9.5, 9.7, 8.1, 3.0, 1.0, 6.8, 4.4,\n",
    "                        1.2, 5.0, 0.3, 9.1, 2.6, 6.6, 3.1, 5.2, 5.5, 1.8,\n",
    "                        9.7, 7.8, 9.4, 8.9, 6.0, 9.2, 0.9, 2.0, 0.5, 3.3,\n",
    "                        3.9, 2.7, 8.3, 3.6, 2.8, 5.4, 1.4, 8.0, 0.7, 9.9,\n",
    "                        7.7, 2.0, 0.1, 8.2, 7.1, 7.3, 7.7, 0.7, 3.6, 1.2,\n",
    "                        8.6, 6.2, 3.3, 0.6, 3.1, 3.3, 7.3, 6.4, 8.9, 4.7,\n",
    "                        1.2, 7.1, 7.6, 5.6, 7.7, 4.9, 5.2, 4.3, 0.3, 1.1],\n",
    "        'Exam Scores': [87.9, 143.6, 123.7, 99.9, 64.5, 67.4, 63.2, 134.0, 106.1, 118.3,\n",
    "                        56.6, 148.6, 130.6, 73.8, 68.7, 73.2, 76.9, 100.8, 91.2, 71.8,\n",
    "                        112.7, 65.3, 79.2, 85.5, 88.5, 126.4, 68.3, 121.0, 63.3, 53.2,\n",
    "                        133.0, 121.9, 124.6, 123.7, 58.6, 87.3, 58.0, 145.6, 114.7,\n",
    "                        77.1, 59.6, 76.2, 86.5, 128.8, 109.7, 143.5, 99.3, 66.1,\n",
    "                        130.8, 124.9, 102.4, 122.6, 95.3, 101.9, 94.5, 53.9, 64.9]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the structure of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# b) Identify the features and the target variable.\n",
    "features = df[['Study Hours']]\n",
    "target = df['Exam Scores']\n",
    "\n",
    "# c) Check for missing values and handle them.\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# No missing values, so no handling required.\n",
    "\n",
    "# d) Visualize the relationship between variables.\n",
    "plt.scatter(df['Study Hours'], df['Exam Scores'])\n",
    "plt.title('Study Hours vs Exam Scores')\n",
    "plt.xlabel('Study Hours')\n",
    "plt.ylabel('Exam Scores')\n",
    "plt.show()\n",
    "\n",
    "# Step 2: Data Preprocessing\n",
    "\n",
    "# a) Split the dataset into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# b) Standardize the independent variables using appropriate scaling techniques.\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 3: Linear Regression Model\n",
    "\n",
    "# a) Train a linear regression model on the training data.\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# b) Evaluate the performance on the testing data.\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'MAE: {mae}')\n",
    "print(f'MSE: {mse}')\n",
    "print(f'R-squared: {r2}')\n",
    "\n",
    "# c) Interpret the coefficients of the linear regression model.\n",
    "coefficients = model.coef_\n",
    "intercept = model.intercept_\n",
    "\n",
    "print(f'Coefficients: {coefficients}')\n",
    "print(f'Intercept: {intercept}')\n",
    "\n",
    "# Step 4: Model Improvement\n",
    "\n",
    "# a) No feature engineering is needed in this simple example.\n",
    "\n",
    "# b) Re-train the linear regression model on the updated dataset.\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# c) Evaluate the performance of the improved model.\n",
    "y_pred_updated = model.predict(X_test_scaled)\n",
    "\n",
    "mae_updated = mean_absolute_error(y_test, y_pred_updated)\n",
    "mse_updated = mean_squared_error(y_test, y_pred_updated)\n",
    "r2_updated = r2_score(y_test, y_pred_updated)\n",
    "\n",
    "print(f'Improved Model - MAE: {mae_updated}')\n",
    "print(f'Improved Model - MSE: {mse_updated}')\n",
    "print(f'Improved Model - R-squared: {r2_updated}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe9584d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
